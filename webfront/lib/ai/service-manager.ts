// AI Service Configuration and Management
// Handles API key validation, fallback logic, and error handling

export interface TranscriptionResult {
    text: string
    segments: Array<{
        start: number
        end: number
        text: string
    }>
}

export interface AnalysisResult {
    summary: string
    highlights: Array<{
        start: number
        end: number
        reason: string
    }>
    jumpCuts: Array<{
        start: number
        end: number
        reason: string
    }>
    keywords?: string[]
    visual_style?: {
        color_grading?: string
        apply_blur?: boolean
        pacing?: string
    }
    subtitle_settings?: {
        position?: string
        highlight_color?: string
    }
}

export class AIServiceManager {
    private googleAIKey: string | undefined
    private openAIKey: string | undefined

    constructor() {
        this.googleAIKey = process.env.GOOGLE_AI_API_KEY
        this.openAIKey = process.env.OPENAI_API_KEY
    }

    // Check which services are available
    getAvailableServices(): string[] {
        const services: string[] = []
        if (this.googleAIKey) services.push('google-ai')
        if (this.openAIKey) services.push('whisper')
        return services
    }

    // Transcribe with automatic fallback
    async transcribe(videoBlob: Blob): Promise<TranscriptionResult> {
        const errors: Array<{ service: string; error: any }> = []

        // Try Google AI first (free tier)
        if (this.googleAIKey) {
            try {
                console.log('ü§ñ Attempting transcription with Google AI (New SDK)...')
                return await this.transcribeWithGoogleAI(videoBlob)
            } catch (error) {
                console.error('‚ùå Google AI failed:', error)
                errors.push({ service: 'Google AI', error })
            }
        }

        // Fallback to Whisper
        if (this.openAIKey) {
            try {
                console.log('üéôÔ∏è Attempting transcription with Whisper...')
                return await this.transcribeWithWhisper(videoBlob)
            } catch (error) {
                console.error('‚ùå Whisper failed:', error)
                errors.push({ service: 'Whisper', error })
            }
        }

        // Last resort: Mock service (for development stability)
        console.log('‚ö†Ô∏è All AI services failed, using Mock fallback for stability...')
        return this.mockTranscription()
    }

    // Mock transcription for development
    private mockTranscription(): TranscriptionResult {
        return {
            text: "‡∏ô‡∏µ‡πà‡∏Ñ‡∏∑‡∏≠‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏£‡∏∞‡∏ö‡∏ö ‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å AI Service ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ‡πÉ‡∏ô‡∏Ç‡∏ì‡∏∞‡∏ô‡∏µ‡πâ ‡∏£‡∏∞‡∏ö‡∏ö‡∏à‡∏∂‡∏á‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≥‡∏•‡∏≠‡∏á‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡πÑ‡∏î‡πâ",
            segments: [
                { start: 0, end: 3, text: "‡∏ô‡∏µ‡πà‡∏Ñ‡∏∑‡∏≠‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á" },
                { start: 3, end: 6, text: "‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏£‡∏∞‡∏ö‡∏ö" },
                { start: 6, end: 10, text: "‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å AI Service ‡πÑ‡∏°‡πà‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô" },
                { start: 10, end: 15, text: "‡∏£‡∏∞‡∏ö‡∏ö‡∏à‡∏∂‡∏á‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≥‡∏•‡∏≠‡∏á‡πÅ‡∏ó‡∏ô" }
            ]
        }
    }

    // Google AI (Gemini) transcription using new SDK
    private async transcribeWithGoogleAI(
        videoBlob: Blob
    ): Promise<TranscriptionResult> {
        const { GoogleGenAI } = require('@google/genai')
        const ai = new GoogleGenAI({ apiKey: this.googleAIKey })

        // Convert to base64
        const arrayBuffer = await videoBlob.arrayBuffer()
        const base64Video = Buffer.from(arrayBuffer).toString('base64')

        // Check file size (Gemini has limits)
        const sizeMB = videoBlob.size / (1024 * 1024)
        if (sizeMB > 50) {
            throw new Error(`Video too large for Google AI: ${sizeMB.toFixed(2)}MB (max 50MB)`)
        }

        const prompt = `‡∏ñ‡∏≠‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏à‡∏≤‡∏Å‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡∏ô‡∏µ‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢ ‡πÅ‡∏•‡∏∞‡∏™‡πà‡∏á‡∏Ñ‡∏∑‡∏ô‡πÄ‡∏õ‡πá‡∏ô JSON ‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ô‡∏µ‡πâ:

{
  "text": "‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏ó‡∏µ‡πà‡∏ñ‡∏≠‡∏î‡πÑ‡∏î‡πâ",
  "segments": [
    {"start": 0.0, "end": 2.5, "text": "‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡πÅ‡∏£‡∏Å"},
    {"start": 2.5, "end": 5.0, "text": "‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡∏ó‡∏µ‡πà‡∏™‡∏≠‡∏á"}
  ]
}

‡∏Å‡∏é:
- ‡πÅ‡∏ö‡πà‡∏á‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡∏•‡∏∞ 2-5 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ
- ‡∏ñ‡∏≠‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÉ‡∏´‡πâ‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏•‡∏∞‡∏Ñ‡∏£‡∏ö‡∏ñ‡πâ‡∏ß‡∏ô
- ‡∏™‡πà‡∏á‡∏Ñ‡∏∑‡∏ô‡πÄ‡∏â‡∏û‡∏≤‡∏∞ JSON ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢`

        const response = await ai.models.generateContent({
            model: 'gemini-2.5-flash',
            contents: [
                {
                    role: 'user',
                    parts: [
                        { text: prompt },
                        {
                            inlineData: {
                                mimeType: 'video/mp4',
                                data: base64Video
                            }
                        }
                    ]
                }
            ]
        })

        const responseText = response.text
        if (!responseText) {
            throw new Error('Empty response from Google AI')
        }

        // Extract JSON from response
        const jsonMatch = responseText.match(/\{[\s\S]*\}/)
        if (!jsonMatch) {
            throw new Error('Invalid JSON response from Google AI')
        }

        // Sanitize JSON before parsing (remove control characters)
        const sanitizedJson = jsonMatch[0]
            .replace(/[\u0000-\u001F\u007F-\u009F]/g, '') // Remove control characters
            .replace(/\\n/g, ' ') // Replace literal \n with space
            .replace(/\\r/g, '') // Remove literal \r
            .replace(/\\t/g, ' ') // Replace literal \t with space

        const parsed = JSON.parse(sanitizedJson)

        // Validate response structure
        if (!parsed.text || !Array.isArray(parsed.segments)) {
            throw new Error('Invalid response structure from Google AI')
        }

        console.log(`‚úÖ Google AI transcribed: ${parsed.segments.length} segments`)
        return parsed
    }

    // Whisper API transcription
    private async transcribeWithWhisper(
        videoBlob: Blob
    ): Promise<TranscriptionResult> {
        const formData = new FormData()
        formData.append('file', videoBlob, 'video.mp4')
        formData.append('model', 'whisper-1')
        formData.append('response_format', 'verbose_json')
        formData.append('language', 'th')
        formData.append('timestamp_granularities[]', 'segment')

        const response = await fetch('https://api.openai.com/v1/audio/transcriptions', {
            method: 'POST',
            headers: {
                Authorization: `Bearer ${this.openAIKey}`,
            },
            body: formData,
        })

        if (!response.ok) {
            const errorText = await response.text()
            throw new Error(`Whisper API error (${response.status}): ${errorText}`)
        }

        const result = await response.json()

        // Validate response
        if (!result.text || !Array.isArray(result.segments)) {
            throw new Error('Invalid response structure from Whisper')
        }

        console.log(`‚úÖ Whisper transcribed: ${result.segments.length} segments`)
        return result
    }

    // Analyze transcript with Gemini (optional enhancement)
    async analyzeTranscript(transcript: TranscriptionResult): Promise<AnalysisResult | null> {
        // If using mock transcription, return mock analysis
        if (transcript.text.includes("‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≥‡∏•‡∏≠‡∏á")) {
            return {
                summary: "‡∏ô‡∏µ‡πà‡∏Ñ‡∏∑‡∏≠‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏à‡∏≥‡∏•‡∏≠‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö",
                highlights: [
                    { start: 0, end: 3, reason: "‡∏à‡∏∏‡∏î‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏ô‡πà‡∏≤‡∏™‡∏ô‡πÉ‡∏à" }
                ],
                jumpCuts: [],
                keywords: ["‡∏ó‡∏î‡∏™‡∏≠‡∏ö", "‡∏à‡∏≥‡∏•‡∏≠‡∏á"]
            }
        }

        if (!this.googleAIKey) {
            console.log('‚ö†Ô∏è No Google AI key, skipping analysis')
            return null
        }

        try {
            const { GoogleGenAI } = require('@google/genai')
            const ai = new GoogleGenAI({ apiKey: this.googleAIKey })

            const prompt = `‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå transcript ‡∏ô‡∏µ‡πâ‡πÅ‡∏•‡∏∞‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡∏î‡∏ï‡πà‡∏≠‡πÅ‡∏ö‡∏ö‡∏°‡∏∑‡∏≠‡∏≠‡∏≤‡∏ä‡∏µ‡∏û:

${transcript.text}

‡∏™‡πà‡∏á‡∏Ñ‡∏∑‡∏ô‡πÄ‡∏õ‡πá‡∏ô JSON ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô:
{
  "summary": "‡∏™‡∏£‡∏∏‡∏õ‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡πÅ‡∏•‡∏∞‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå‡∏Ç‡∏≠‡∏á‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠",
  "visual_style": {
    "color_grading": "vibrant", // vibrant, cinematic, natural, black_and_white
    "apply_blur": false, // true only for vertical video with horizontal background
    "pacing": "fast" // fast, medium, slow
  },
  "subtitle_settings": {
    "position": "bottom", // bottom, center, top (center for shorts/reels)
    "highlight_color": "yellow" // yellow, green, cyan
  },
  "highlights": [
    {
      "start": 5.0, 
      "end": 10.0, 
      "reason": "‡∏à‡∏∏‡∏î‡∏û‡∏µ‡∏Ñ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏ô‡πâ‡∏ô",
      "effects": {
        "zoom": {
          "intensity": "medium", // subtle, medium, strong
          "easing": "ease-in-out"
        }
      }
    }
  ],
  "jumpCuts": [
    {
      "start": 0.0,
      "end": 1.5,
      "reason": "‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏á‡∏µ‡∏¢‡∏ö/‡∏û‡∏π‡∏î‡∏ú‡∏¥‡∏î"
    }
  ],
  "keywords": [
    "‡∏Ñ‡∏≥‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç1", "‡∏Ñ‡∏≥‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç2"
  ]
}

‡πÄ‡∏á‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏Ç‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏à (Smart Tool Selection):
1. **Visual Style**:
   - **Color Grading**: ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å 'vibrant' ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Vlog/Travel, 'cinematic' ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏´‡∏ô‡∏±‡∏á‡∏™‡∏±‡πâ‡∏ô, 'natural' ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏™‡∏±‡∏°‡∏†‡∏≤‡∏©‡∏ì‡πå
   - **Blur**: ‡πÉ‡∏ä‡πâ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏ö‡∏•‡∏≠‡∏Ç‡∏≠‡∏ö ‡∏´‡∏£‡∏∑‡∏≠‡∏û‡∏∑‡πâ‡∏ô‡∏´‡∏•‡∏±‡∏á‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏™‡∏ß‡∏¢‡∏á‡∏≤‡∏°

2. **Subtitles**:
   - **Position**: ‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô Vertical Video (Shorts/Reels) ‡πÉ‡∏´‡πâ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å 'center' ‡∏´‡∏£‡∏∑‡∏≠ 'bottom' ‡∏ó‡∏µ‡πà‡∏™‡∏π‡∏á‡∏Ç‡∏∂‡πâ‡∏ô‡∏°‡∏≤‡∏´‡∏ô‡πà‡∏≠‡∏¢‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÑ‡∏°‡πà‡πÉ‡∏´‡πâ‡πÇ‡∏î‡∏ô UI ‡∏ö‡∏±‡∏á
   - **Highlight**: ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏™‡∏µ‡∏ó‡∏µ‡πà‡∏ï‡∏±‡∏î‡∏Å‡∏±‡∏ö‡∏û‡∏∑‡πâ‡∏ô‡∏´‡∏•‡∏±‡∏á‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠ (Yellow ‡∏Ñ‡∏∑‡∏≠‡∏Ñ‡πà‡∏≤‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î)

3. **Highlights & Zoom**:
   - ‡∏≠‡∏¢‡πà‡∏≤ Zoom ‡∏û‡∏£‡πà‡∏≥‡πÄ‡∏û‡∏£‡∏∑‡πà‡∏≠! ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏à‡∏∏‡∏î‡∏ó‡∏µ‡πà‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏à‡∏£‡∏¥‡∏á‡πÜ
   - Zoom ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏ô‡πâ‡∏ô‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå ‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏∞

4. **Jump Cuts**:
   - ‡∏ï‡∏±‡∏î‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏á‡∏µ‡∏¢‡∏ö‡πÄ‡∏Å‡∏¥‡∏ô 0.5 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ ‡πÅ‡∏•‡∏∞‡∏Ñ‡∏≥‡∏ü‡∏∏‡πà‡∏°‡πÄ‡∏ü‡∏∑‡∏≠‡∏¢
`

            const response = await ai.models.generateContent({
                model: 'gemini-2.5-flash',
                contents: [
                    {
                        role: 'user',
                        parts: [{ text: prompt }]
                    }
                ]
            })

            const responseText = response.text
            const jsonMatch = responseText?.match(/\{[\s\S]*\}/)

            if (jsonMatch) {
                return JSON.parse(jsonMatch[0])
            }
        } catch (error) {
            console.error('Analysis failed:', error)
        }

        return null
    }
}
